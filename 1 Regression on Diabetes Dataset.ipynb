{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf450b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = datasets.load_diabetes(as_frame=True, return_X_y=False)\n",
    "X = data.data\n",
    "y = data.target\n",
    "X['gender'] = pd.cut(X[\"sex\"], bins=[-1,0,1], labels=[0,1])\n",
    "X = X.drop(['sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1baab784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2153db06",
   "metadata": {},
   "source": [
    "## Big Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95047c7",
   "metadata": {},
   "source": [
    "Given past diabetes data, we want to find out if a person is at risk of diabetes based on certain input features\n",
    "Model we create will be used by technicians to find the risk of diabetes\n",
    "Since we have the diabetest dataset, this will be a supervised learning problem. Will also explore unsupervised in the end (Nearest Neighbors with Kernel)\n",
    "We will start this off as a multiple regression problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69622b6c",
   "metadata": {},
   "source": [
    "While working on this as a regression problem, we will use RMSE for measuriing model performance\n",
    "Will switch to F1 score when we tackle this as a binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a29ffb",
   "metadata": {},
   "source": [
    "## Set aside the test set\n",
    "Lets set aside some test data set to check our final model performance. Done before we start exporing the data and using it for training.\n",
    "Question now is, how much do we set aside for test set? Since diabetes dataset has only 442 records, we need to set aside a decent % for test set to be able to find True error. So we will set aside 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74aadeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter\n",
    "test_ratio = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1049e7ce",
   "metadata": {},
   "source": [
    "### option 1 is to randomly split data\n",
    "But the issue is that our training set data will change evry time we run our try training the model. Eventually all the data will be part of training so defeats the purpose of have a test set that generalizes true error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5c11e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a shuffled out of order array of len(X) elements\n",
    "shuffled_indices = np.random.permutation(len(X))\n",
    "test_set_size = int(len(X)*test_ratio)\n",
    "\n",
    "test_indices = shuffled_indices[:test_set_size]\n",
    "train_indices = shuffled_indices[test_set_size:]\n",
    "train_X = X.iloc[train_indices]\n",
    "train_y = y[train_indices]\n",
    "test_X = X.iloc[test_indices]\n",
    "test_y = y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46940284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 310, 132, 132)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(train_y), len(test_X), len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6d2c0",
   "metadata": {},
   "source": [
    "### option 2 is to use sklearn's split capability\n",
    "But the issues with option 1 remain even if we set the random_state parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4160874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = test_ratio, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74a8531f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 309, 133, 133)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(train_y), len(test_X), len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759e819",
   "metadata": {},
   "source": [
    "### option 3 is the split so that each subgroup is represented well in test set \n",
    "diabetes dataset has sex as an attribute that we can possibly use to define subgroups that need representation in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de56352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "data = pd.concat([X,y], axis=1)\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size = test_ratio, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"gender\"]):\n",
    "    train_set = data.iloc[train_index]\n",
    "    test_set = data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc77053f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 133)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8f260",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "All the columns here are numerical and already normalized (centered around zero)\n",
    "So we don't have the task of converting non-numerical columns into one-hot-encoding or scaling them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "174605e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896663</td>\n",
       "      <td>0.051519</td>\n",
       "      <td>0.542207</td>\n",
       "      <td>0.515501</td>\n",
       "      <td>0.325717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>0.896663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196455</td>\n",
       "      <td>0.659817</td>\n",
       "      <td>0.318353</td>\n",
       "      <td>0.290600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>0.051519</td>\n",
       "      <td>-0.196455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.738493</td>\n",
       "      <td>-0.398577</td>\n",
       "      <td>-0.273697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>0.542207</td>\n",
       "      <td>0.659817</td>\n",
       "      <td>-0.738493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617857</td>\n",
       "      <td>0.417212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>0.515501</td>\n",
       "      <td>0.318353</td>\n",
       "      <td>-0.398577</td>\n",
       "      <td>0.617857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.464670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s6</th>\n",
       "      <td>0.325717</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>-0.273697</td>\n",
       "      <td>0.417212</td>\n",
       "      <td>0.464670</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          s1        s2        s3        s4        s5        s6\n",
       "s1  1.000000  0.896663  0.051519  0.542207  0.515501  0.325717\n",
       "s2  0.896663  1.000000 -0.196455  0.659817  0.318353  0.290600\n",
       "s3  0.051519 -0.196455  1.000000 -0.738493 -0.398577 -0.273697\n",
       "s4  0.542207  0.659817 -0.738493  1.000000  0.617857  0.417212\n",
       "s5  0.515501  0.318353 -0.398577  0.617857  1.000000  0.464670\n",
       "s6  0.325717  0.290600 -0.273697  0.417212  0.464670  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['s1','s2','s3','s4','s5','s6']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13108fdf",
   "metadata": {},
   "source": [
    "## Data Clearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9b99161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   age     442 non-null    float64 \n",
      " 1   bmi     442 non-null    float64 \n",
      " 2   bp      442 non-null    float64 \n",
      " 3   s1      442 non-null    float64 \n",
      " 4   s2      442 non-null    float64 \n",
      " 5   s3      442 non-null    float64 \n",
      " 6   s4      442 non-null    float64 \n",
      " 7   s5      442 non-null    float64 \n",
      " 8   s6      442 non-null    float64 \n",
      " 9   gender  442 non-null    category\n",
      " 10  target  442 non-null    float64 \n",
      "dtypes: category(1), float64(10)\n",
      "memory usage: 35.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f6f5e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">age</th>\n",
       "      <th colspan=\"2\" halign=\"left\">bmi</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">s6</th>\n",
       "      <th colspan=\"8\" halign=\"left\">target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-0.076395</th>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.019656</td>\n",
       "      <td>0.052977</td>\n",
       "      <td>-0.107226</td>\n",
       "      <td>-0.068176</td>\n",
       "      <td>-0.012780</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>0.067136</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.043313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012384</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>28.0</td>\n",
       "      <td>97.857143</td>\n",
       "      <td>53.670265</td>\n",
       "      <td>37.0</td>\n",
       "      <td>60.75</td>\n",
       "      <td>89.5</td>\n",
       "      <td>111.25</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.070859</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.022373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038357</td>\n",
       "      <td>-0.038357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.069383</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.046085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079778</td>\n",
       "      <td>-0.079778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.00</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.00</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.053516</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048974</td>\n",
       "      <td>0.048974</td>\n",
       "      <td>0.048974</td>\n",
       "      <td>0.048974</td>\n",
       "      <td>0.048974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.030996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019633</td>\n",
       "      <td>0.019633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>102.00</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.051671</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.020045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020045</td>\n",
       "      <td>-0.020045</td>\n",
       "      <td>-0.020045</td>\n",
       "      <td>-0.020045</td>\n",
       "      <td>-0.020045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.084886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.130252</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.027310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.027310</td>\n",
       "      <td>-0.027310</td>\n",
       "      <td>-0.027310</td>\n",
       "      <td>-0.027310</td>\n",
       "      <td>-0.027310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131470</td>\n",
       "      <td>0.131470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317.0</td>\n",
       "      <td>317.00</td>\n",
       "      <td>317.0</td>\n",
       "      <td>317.00</td>\n",
       "      <td>317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.141322</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096197</td>\n",
       "      <td>0.096197</td>\n",
       "      <td>0.096197</td>\n",
       "      <td>0.096197</td>\n",
       "      <td>0.096197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061054</td>\n",
       "      <td>0.061054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.00</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.00</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.145012</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.003698</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>-0.020045</td>\n",
       "      <td>-0.011871</td>\n",
       "      <td>-0.003698</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>0.012648</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.060618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051734</td>\n",
       "      <td>0.052770</td>\n",
       "      <td>2.0</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>41.012193</td>\n",
       "      <td>248.0</td>\n",
       "      <td>262.50</td>\n",
       "      <td>277.0</td>\n",
       "      <td>291.50</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.155345</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.023546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023546</td>\n",
       "      <td>0.023546</td>\n",
       "      <td>0.023546</td>\n",
       "      <td>0.023546</td>\n",
       "      <td>0.023546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081764</td>\n",
       "      <td>0.081764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242.0</td>\n",
       "      <td>242.00</td>\n",
       "      <td>242.0</td>\n",
       "      <td>242.00</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.185234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.00</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age                                                              \\\n",
       "          count      mean       std       min       25%       50%       75%   \n",
       "s4                                                                            \n",
       "-0.076395  28.0 -0.019656  0.052977 -0.107226 -0.068176 -0.012780  0.022638   \n",
       "-0.070859   1.0  0.009016       NaN  0.009016  0.009016  0.009016  0.009016   \n",
       "-0.069383   1.0  0.001751       NaN  0.001751  0.001751  0.001751  0.001751   \n",
       "-0.053516   1.0  0.048974       NaN  0.048974  0.048974  0.048974  0.048974   \n",
       "-0.051671   1.0 -0.020045       NaN -0.020045 -0.020045 -0.020045 -0.020045   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 0.130252   1.0 -0.027310       NaN -0.027310 -0.027310 -0.027310 -0.027310   \n",
       " 0.141322   1.0  0.096197       NaN  0.096197  0.096197  0.096197  0.096197   \n",
       " 0.145012   2.0 -0.003698  0.023117 -0.020045 -0.011871 -0.003698  0.004475   \n",
       " 0.155345   1.0  0.023546       NaN  0.023546  0.023546  0.023546  0.023546   \n",
       " 0.185234   1.0  0.005383       NaN  0.005383  0.005383  0.005383  0.005383   \n",
       "\n",
       "                      bmi            ...        s6           target  \\\n",
       "                max count      mean  ...       75%       max  count   \n",
       "s4                                   ...                              \n",
       "-0.076395  0.067136  28.0 -0.043313  ...  0.012384  0.073480   28.0   \n",
       "-0.070859  0.009016   1.0 -0.022373  ... -0.038357 -0.038357    1.0   \n",
       "-0.069383  0.001751   1.0 -0.046085  ... -0.079778 -0.079778    1.0   \n",
       "-0.053516  0.048974   1.0 -0.030996  ...  0.019633  0.019633    1.0   \n",
       "-0.051671 -0.020045   1.0 -0.084886  ... -0.046641 -0.046641    1.0   \n",
       "...             ...   ...       ...  ...       ...       ...    ...   \n",
       " 0.130252 -0.027310   1.0  0.047685  ...  0.131470  0.131470    1.0   \n",
       " 0.141322  0.096197   1.0  0.051996  ...  0.061054  0.061054    1.0   \n",
       " 0.145012  0.012648   2.0  0.060618  ...  0.051734  0.052770    2.0   \n",
       " 0.155345  0.023546   1.0  0.061696  ...  0.081764  0.081764    1.0   \n",
       " 0.185234  0.005383   1.0  0.034751  ...  0.073480  0.073480    1.0   \n",
       "\n",
       "                                                                       \n",
       "                 mean        std    min     25%    50%     75%    max  \n",
       "s4                                                                     \n",
       "-0.076395   97.857143  53.670265   37.0   60.75   89.5  111.25  283.0  \n",
       "-0.070859   84.000000        NaN   84.0   84.00   84.0   84.00   84.0  \n",
       "-0.069383  114.000000        NaN  114.0  114.00  114.0  114.00  114.0  \n",
       "-0.053516  102.000000        NaN  102.0  102.00  102.0  102.00  102.0  \n",
       "-0.051671   90.000000        NaN   90.0   90.00   90.0   90.00   90.0  \n",
       "...               ...        ...    ...     ...    ...     ...    ...  \n",
       " 0.130252  317.000000        NaN  317.0  317.00  317.0  317.00  317.0  \n",
       " 0.141322  230.000000        NaN  230.0  230.00  230.0  230.00  230.0  \n",
       " 0.145012  277.000000  41.012193  248.0  262.50  277.0  291.50  306.0  \n",
       " 0.155345  242.000000        NaN  242.0  242.00  242.0  242.00  242.0  \n",
       " 0.185234   84.000000        NaN   84.0   84.00   84.0   84.00   84.0  \n",
       "\n",
       "[66 rows x 72 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('s4').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252fb01",
   "metadata": {},
   "source": [
    "### There seems to be some \"floor\" applied to the s4 value. I am not sure if there is a natural minimum of this parameter or this is just a data set issue\n",
    "So will ignore this for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7f1a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d37fad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_set.drop(\"target\", axis=1), train_set['target']\n",
    "test_X, test_y = test_set.drop(\"target\", axis=1), test_set['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae197cbd",
   "metadata": {},
   "source": [
    "### Lets try out some regressors and see which one have the most promise\n",
    "We will then further work on the most promissing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5acf67af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53.54012993960013, 5.022513371288058)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(train_X, train_y)\n",
    "lin_scores = cross_val_score(linear_reg, train_X, train_y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse = np.sqrt(-lin_scores)\n",
    "np.mean(lin_rmse), np.std(lin_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99aa4e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78.52115056808245, 3.4678949953942144)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr.fit(train_X, train_y)\n",
    "svr_scores = cross_val_score(svr, train_X, train_y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "svr_rmse = np.sqrt(-svr_scores)\n",
    "np.mean(svr_rmse), np.std(svr_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "931d1677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93.46606353559879, 9.676018255275071)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svr = LinearSVR()\n",
    "linear_svr.fit(train_X, train_y)\n",
    "lin_svr_scores = cross_val_score(linear_svr, train_X, train_y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_svr_rmse = np.sqrt(-lin_svr_scores)\n",
    "np.mean(lin_svr_rmse), np.std(lin_svr_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "236e1539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.26613152087876, 3.0538237785038684)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_svr = SVR(kernel=\"poly\")\n",
    "poly_svr.fit(train_X, train_y)\n",
    "poly_svr_scores = cross_val_score(poly_svr, train_X, train_y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "poly_svr_rmse = np.sqrt(-poly_svr_scores)\n",
    "np.mean(poly_svr_rmse), np.std(poly_svr_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89328240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78.69991754768655, 13.158233430806582)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(train_X, train_y)\n",
    "dtr_scores = cross_val_score(dtr, train_X, train_y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "dtr_rmse = np.sqrt(-dtr_scores)\n",
    "np.mean(dtr_rmse), np.std(dtr_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feab2859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.57164469480931, 4.6779219400619265)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(train_X, train_y)\n",
    "rfr_scores = cross_val_score(rfr, train_X, train_y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rfr_rmse = np.sqrt(-rfr_scores)\n",
    "np.mean(rfr_rmse), np.std(rfr_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9de1b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58.391390015957484, 5.517313703149795)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "knn_scores = cross_val_score(knn, train_X, train_y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "knn_rmse = np.sqrt(-knn_scores)\n",
    "np.mean(knn_rmse), np.std(knn_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39630b7e",
   "metadata": {},
   "source": [
    "### fine tune promissing models. \n",
    "KNN, Random Forest, and Linear Regressor seem to have the lowest mean RMSE based on cross valdiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d4615fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "              param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                           'n_estimators': [1, 10, 30]},\n",
       "                          {'bootstrap': [False], 'max_features': [2, 4, 6, 8],\n",
       "                           'n_estimators': [3, 10]}],\n",
       "              return_train_score=True, scoring='neg_mean_squared_error'),\n",
       " RandomForestRegressor(max_features=8, n_estimators=30),\n",
       " 55.12587151532169)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators': [1,10,30], 'max_features':[2,4,6,8]},\n",
    "    {'bootstrap':[False], 'n_estimators':[3,10], 'max_features':[2,4,6,8]}\n",
    "]\n",
    "grid = GridSearchCV(rfr, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid.fit(train_X, train_y), grid.best_estimator_, np.sqrt(-grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54a13fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GridSearchCV(cv=5, estimator=KNeighborsRegressor(),\n",
       "              param_grid=[{'algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                         'brute'],\n",
       "                           'n_neighbors': [5, 10, 20]}],\n",
       "              return_train_score=True, scoring='neg_mean_squared_error'),\n",
       " KNeighborsRegressor(n_neighbors=10),\n",
       " 55.84335145895315)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'n_neighbors':[5,10,20], 'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "]\n",
    "grid = GridSearchCV(knn, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid.fit(train_X, train_y), grid.best_estimator_, np.sqrt(-grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c7ea77",
   "metadata": {},
   "source": [
    "### no params for Linear Reg\n",
    "So we will try Ridge and Lasso regression with various alpha values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aee38e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GridSearchCV(cv=5, estimator=Ridge(),\n",
       "              param_grid=[{'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}],\n",
       "              return_train_score=True, scoring='neg_mean_squared_error'),\n",
       " Ridge(alpha=0.0001),\n",
       " 53.88554602191953,\n",
       " array([  -9.27893714,  485.20515584,  398.46438269, -909.72655032,\n",
       "         590.48360399,  105.34716445,  192.12083402,  891.35461304,\n",
       "         -19.09629896,  -23.16317879]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "param_grid = [{'alpha':[0.0001, 0.001, 0.01,0.1,1]}]\n",
    "ridge = Ridge()\n",
    "grid = GridSearchCV(ridge, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid.fit(train_X, train_y), grid.best_estimator_, np.sqrt(-grid.best_score_), grid.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40b27077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GridSearchCV(cv=5, estimator=Lasso(),\n",
       "              param_grid=[{'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}],\n",
       "              return_train_score=True, scoring='neg_mean_squared_error'),\n",
       " Lasso(alpha=0.0001),\n",
       " 53.885810861435004,\n",
       " array([  -9.3751195 ,  485.06153318,  398.5557778 , -919.85203406,\n",
       "         599.00981053,  109.52259889,  192.6452401 ,  895.3321561 ,\n",
       "         -19.16910918,  -23.16339489]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()\n",
    "grid = GridSearchCV(lasso, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid.fit(train_X, train_y), grid.best_estimator_, np.sqrt(-grid.best_score_), grid.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f8550",
   "metadata": {},
   "source": [
    "## Test Set Results\n",
    "As of now it lools like Ridge/Lasso regressor may be the one with best result. lets evaluate it with our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b98bd54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.20616862110966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "ridge = Ridge(alpha=0.0001)\n",
    "ridge.fit(train_X, train_y)\n",
    "prediction = ridge.predict(test_X)\n",
    "final_rmse = np.sqrt(mean_squared_error(test_y, prediction))\n",
    "print(final_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64524b9",
   "metadata": {},
   "source": [
    "## Observation\n",
    "There seems to be significant deviation between the train RMSE (3.88554602191953) and test RMSE (57.20616862110966). Which means that we have an issue with variance. We may need a better model or need to train this model longer to better fit the data. BUt there is no \"train longer\" option for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328de2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
